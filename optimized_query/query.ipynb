{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  ðŸš¨ Note!\n",
    "> The given query contained several syntax issues, including misspelled column names and typographical errors, such as missing commas in the `SELECT` statement. I did not consider these basic syntax fixes as part of the optimizations I made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Creating indexes for optimization\n",
    "CREATE INDEX idx_clickup_name ON ClickUp(Name);\n",
    "CREATE INDEX idx_float_name ON Float(Name);\n",
    "CREATE INDEX idx_clickup_hours ON ClickUp(hours);\n",
    "\n",
    "-- Optimized query\n",
    "SELECT\n",
    "    c.Name,\n",
    "    f.Role,\n",
    "    SUM(c.hours) AS Total_Tracked_Hours,\n",
    "    SUM(f.Estimed_Hours) AS Total_Allocated_Hours\n",
    "FROM\n",
    "    ClickUp c\n",
    "JOIN\n",
    "    Float f\n",
    "    ON c.Name = f.Name\n",
    "WHERE\n",
    "    c.hours > 0   \n",
    "GROUP BY\n",
    "    c.Name,\n",
    "    f.Role\n",
    "HAVING\n",
    "    SUM(c.hours) > 100\n",
    "ORDER BY\n",
    "    Total_Allocated_Hours DESC;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "GROUP BY\n",
    "    c.Name,\n",
    "    f.Role,\n",
    "    c.Date\n",
    "\n",
    "-- OR\n",
    "\n",
    "MAX(c.Date) AS Latest_Date ---> Not necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since the `date` column isn't in the `GROUP BY` clause, I would have included it in the `GROUP BY` clause or replaced it with `MAX(c.Date)`, This makes the query simpler and keeps it logically correct. \n",
    "\n",
    "But I prefered removing unnecessary columns in the `GROUP BY` clause or using `MAX(c.Date)` in the SELECT clause if it's not essential to my output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Index on `Name` in ClickUp and Flaot tables to optimize the JOIN operation\n",
    "CREATE INDEX idx_clickup_name ON ClickUp(Name);\n",
    "CREATE INDEX idx_float_name ON Float(Name);\n",
    "\n",
    "-- Index on `hours` in ClickUp table to optimize the aggregation and filtering in HAVING clause\n",
    "CREATE INDEX idx_clickup_hours ON ClickUp(hours);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I prefer indexing the `Name` column in both the `Clickup` and `Float` tables and the `hours` column on the `Clickup` table to improve the efficiency of the `JOIN` operation.  \n",
    "\n",
    "    The `Name` indexes will ensure that the database can efficiently match rows between the `ClickUp` and `Float` tables during the `JOIN` operation, also index on `hours` in the `ClickUp` table helps optimize the `SUM(c.hours)` aggregation and makes the filtering in the `HAVING` clause faster.\n",
    "\n",
    "    basically since indexing is like an index in a book, it helps the database quickly locate the data without having to scan the entire table \n",
    "\n",
    "    **Reason for choosing Indexing over partition:**\n",
    "    Indexing is generally more beneficial for tables that are not exceedingly large, where the overhead of maintaining partitions might not be justified and it also increases complexity in terms of table management, especially when adding or removing partitions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Performance Result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  ðŸš¨ Note!\n",
    "> I used a **copy** of the data ingested to my Postgres Database from the ETL process to carry out the optimization tests, and I used `Dbeaver` as my Database Management tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <figure style=\"text-align: center; margin: 0 10px;\">\n",
    "        <img src=\"../static/Optimized-shot.png\" alt=\"Optimized Query\" width=\"500\" />\n",
    "    </figure>\n",
    "    <figure style=\"text-align: center; margin: 0 10px;\">\n",
    "        <img src=\"../static/not_optimized-shot.png\" alt=\"Not Optimized\" width=\"500\" />\n",
    "    </figure>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##                          Optimized query (Left Image) | Not Optimized Query (Right Image)\n",
    "1) **Execution Time**\n",
    "    Without Optimization: Execution time is 4.7 ms.\n",
    "    With Optimization: Execution time is 2.067 ms.\n",
    "\n",
    "    The optimized query is almost half the execution time of the non optimized one, which is a significant improvement.\n",
    "\n",
    "2)  **Cost**\n",
    "    Without Optimization: The total cost is 301.00..303.36.\n",
    "    With Optimization: The total cost is 89.05..89.13.\n",
    "\n",
    "    The cost reduction from 301 to 89 shows that the query planner chose a more efficient execution plan with the optimizations. Lower cost generally indicates better resource utilization (e.g., CPU, memory, I/O).\n",
    "\n",
    "3) **Without Optimization**\n",
    "    Sort Key: `sum(f.estimated_hours)` is done using the quicksort method with a memory usage of 25kB.\n",
    "    The sort takes a longer time with higher cost.\n",
    "    With Optimization:\n",
    "\n",
    "    The sort is done more efficiently with the same quicksort method, but it is faster with reduced cost and time for sorting (2.032 ms vs. 4.655 ms).\n",
    "\n",
    "4) **Join Operation**\n",
    "    Without Optimization: The Hash Join has a cost of 16.98..176.73, and it's joining over 3992 rows.\n",
    "\n",
    "    With Optimization: The Hash Join now costs 1.29..73.75, and the row count is 2924.\n",
    "\n",
    "    The join cost has dropped significantly, and fewer rows are being processed. This could be due to optimizations in filtering, indexing, or better hash join management\n",
    "\n",
    "5) **Filter (Rows Removed)**\n",
    "    Without Optimization: The filter `(SUM(c.hours) > 100)` removes 316 rows.\n",
    "    With Optimization: The filter removes only 1 row.\n",
    "\n",
    "    This indicates that the query optimizer is now effectively filtering unnecessary rows earlier in the query execution, reducing the number of rows that need to be processed in later stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  ðŸš¨ Note! <br>\n",
    "> The dataset used is relatively small and a dataset with a larger size would have been more ideal to carry out performance optimiztions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
